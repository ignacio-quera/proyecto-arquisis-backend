version: '3'
services:
  fastapi_app:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "8000:8000"
    restart: unless-stopped
    networks:
      - mqtt-network
      - app-network
    container_name: fastapi_app
    volumes:
      - ./app:/app/app
    depends_on:
      - db

  fastapi_app_2:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "8001:8000"
    restart: unless-stopped
    networks:
      - mqtt-network
      - app-network
    container_name: fastapi_app_2
    volumes:
      - ./app:/app/app
    depends_on:
      - db

  fastapi_app_3:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "8002:8000"
    restart: unless-stopped
    networks:
      - mqtt-network
      - app-network
    container_name: fastapi_app_3
    volumes:
      - ./app:/app/app
    depends_on:
      - db
    
  db:
    image: postgres:latest
    container_name: db
    networks:
      - app-network
    expose:
      - "5432"
    restart: always
    hostname: db
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: db_development_flights_e0
    volumes:
      - db-volume:/var/lib/postgresql/data
      # To persist the data in the database we have a volume that persist after container deletion
      # and copy the files from the container to the volume.

  listener:
    build:
      context: ./listener
      dockerfile: Dockerfile
    container_name: listener_container
    networks:
      - mqtt-network
    restart: unless-stopped
    volumes:
    - ./listener/:/listener/
    depends_on:
      - fastapi_app

  publisher:
    build:
      context: .
      dockerfile: Dockerfile.pub
    ports:
      - "9001:9001"
    networks:
      - app-network
      - mqtt-network
    container_name: publisher_container
    restart: always
    volumes:
      - ./publisher:/publisher/publisher

  jobmaster:
    container_name: jobmaster
    build:
        context: ./workers
        dockerfile: Dockerfile
    command: uvicorn producer:app --reload --host 0.0.0.0 --port 8000
    volumes:
      - ./workers:/opt/
    ports:
      - "8000:8000"
    environment:
      CELERY_BROKER_URL: ${CELERY_BROKER_URL}
      CELERY_RESULT_BACKEND: ${CELERY_RESULT_BACKEND}
    depends_on:
      - redis-broker
    networks:
      - app-network
  
  workers:
    container_name: workers
    build:
        context: ./workers
        dockerfile: Dockerfile
    deploy:
      # replicas scales containers
      replicas: 1
    # concurrency specifies number of worker
    # purge deletes the broker queue every time it starts up
    command: celery -A consumer.celery_app worker --loglevel=INFO --purge --concurrency=1
    volumes:
      - ./workers:/opt/
    depends_on:
      - jobmaster
    environment:
      CELERY_BROKER_URL: ${CELERY_BROKER_URL}
      CELERY_RESULT_BACKEND: ${CELERY_RESULT_BACKEND}
    networks:
      - app-network

networks:
  app-network:
    driver: bridge
  mqtt-network:
    driver: bridge

volumes: # All the named volumes needed to persist data after container deletion
  db-volume: